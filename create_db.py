from langchain_core.documents import Document
from embed_func import get_embedding_func
from langchain_community.vectorstores import Chroma
import argparse
import os
import shutil
from typing import List
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_community.document_loaders import DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
CHROMA_PATH = "chroma"
DATA_PATH = "data"

url = ["https://www.sberbank.com/ru/s_m_business/open-accounts?utm_source=yandex&utm_medium=cpc&utm_campaign=open-accounts_corporate_perform_god_20220100016_rk436516gr2234_context_search_brand_optimisation_rus_yxprrko%7C111959248%7Cgid%7C5458249861%7Cad%7C16234457890_16234457890%7Cph_id%7C52166801428%7Csrc%7Cnone_search%7Cgeo%7C–ú–æ—Å–∫–≤–∞_213%7C&utm_term=—Å–±–µ—Ä+–ª–µ–≥–∫–∏–π+—Å—Ç–∞—Ä—Ç+—Ç–∞—Ä–∏—Ñ—ã&yclid=18330555996781150207",
       "http://government.ru/sanctions_measures/measure/65/",
       "http://government.ru/sanctions_measures/measure/4/",
       "https://www.nalog.gov.ru/rn77/anticrisis2022/#t2",
       "https://–º—Å–ø.—Ä—Ñ/services/knowledge-base/detail/sistema-bystrykh-platezhey-chto-vazhno-znat/",
       "https://–º—Å–ø.—Ä—Ñ/services/knowledge-base/detail/kak-podgotovitsya-k-proverke-chto-nuzhno-znat/",
       "https://–º—Å–ø.—Ä—Ñ/services/knowledge-base/detail/otchetnost-v-nalogovuyu/",
       "https://www.sberbank.com/ru/s_m_business/actions",
       "https://www.sberbank.com/ru/s_m_business/promo/bc_actions",
       "https://www.sberbank.com/ru/s_m_business/bankingservice/sberpay-qr"]

def main():
    # Check if the database should be cleared (using the --clear flag).
    parser = argparse.ArgumentParser()
    parser.add_argument("--reset", action="store_true", help="Reset the database.")
    args = parser.parse_args()
    if args.reset:
        print("‚ú® Clearing Database")
        clear_database()

    # Create (or update) the data store.
    documents = PDFload_docs()
    chunks = split_docs(documents)
    add_to_chroma(chunks)

    documents = WEBload_docs(urls=url)
    chunks = split_docs(documents)
    add_to_chroma(chunks)


def PDFload_docs():
    documents_loader = PyPDFDirectoryLoader('data/')
    return documents_loader.load()

def WEBload_docs(urls: list):
    # documents_loader = WebBaseLoader(web_paths=urls, show_progress=True, header_template=headers, verify_ssl=False)
    documents_loader = WebBaseLoader(web_paths=urls, header_template=headers, verify_ssl=False)
    return documents_loader.load()

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç—É –Ω–∞ –æ–¥–Ω–æ–π –ø–∞–ø–∫–µ, WebBaseLoader
# https://python.langchain.com/v0.2/docs/integrations/document_loaders/web_base/

# chunk_size=800: –≠—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä –∫–ª–∞—Å—Å–∞ RecursiveCharacterTextSplitter,
# –∫–æ—Ç–æ—Ä—ã–π —É–∫–∞–∑—ã–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö.
# –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –∫–∞–∂–¥—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –±—É–¥–µ—Ç –∏–º–µ—Ç—å –º–∞–∫—Å–∏–º—É–º 800 —Å–∏–º–≤–æ–ª–æ–≤.

# chunk_overlap=80: –≠—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä –∫–ª–∞—Å—Å–∞ RecursiveCharacterTextSplitter,
# –∫–æ—Ç–æ—Ä—ã–π —É–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—Ç—å—Å—è –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏ —Ç–µ–∫—Å—Ç–∞.
# –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –∫–∞–∂–¥—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –±—É–¥–µ—Ç –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—Ç—å—Å—è —Å —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏ –Ω–∞ 80 —Å–∏–º–≤–æ–ª–æ–≤.

def split_docs(documents: list[Document]):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1200,
        chunk_overlap=300,
        length_function=len,
        is_separator_regex=False
    )
    return text_splitter.split_documents(documents)

# ValueError: Batch size * exceeds maximum batch size 166
def add_to_chroma(chunks: List[Document]):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
    db = Chroma(
        persist_directory=CHROMA_PATH,  # –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –≥–¥–µ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞ –¥–∏—Å–∫–µ
        embedding_function=get_embedding_func(),  # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        collection_metadata={"hnsw:space": "cosine"} # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞ -> –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
    )
    # –í—ã—á–∏—Å–ª—è–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞ (—á–∞—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞).
    chunks_with_ids = calculate_chunk_ids(chunks)

    # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
    existing_items = db.get(
        include=[])  # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    existing_ids = set(existing_items["ids"])  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–æ–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    print(f"Number of existing documents in DB: {len(existing_ids)}")

    # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
    new_chunks = []
    for chunk in chunks_with_ids:
        if chunk.metadata["id"] not in existing_ids:
            new_chunks.append(chunk)

    if len(new_chunks):
        print(f"üëâ Adding new documents: {len(new_chunks)}")
        new_chunk_ids = [chunk.metadata["id"] for chunk in new_chunks]

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ 166 —à—Ç—É–∫ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
        batch_size = 166
        for i in range(0, len(new_chunks), batch_size):
            batch_chunks = new_chunks[i:i + batch_size]
            batch_ids = new_chunk_ids[i:i + batch_size]
            db.add_documents(batch_chunks,
                             ids=batch_ids)  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–∫–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤

        db.persist()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –¥–∏—Å–∫
    else:
        print("‚úÖ No new documents to add")

def calculate_chunk_ids(chunks):
    # "data/Adobe....pdf:6:2"
    # Page Source : Page Number : Chunk Index
    last_page_id = None
    current_chunk_index = 0
    for chunk in chunks:
        source = chunk.metadata.get("source")
        page = chunk.metadata.get("page")
        current_page_id = f"{source}:{page}"
    # –ï—Å–ª–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º, —É–≤–µ–ª–∏—á—å—Ç–µ –∏–Ω–¥–µ–∫—Å.
        if current_page_id == last_page_id:
            current_chunk_index += 1
        else:
            current_chunk_index = 0
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ id –¥–ª—è —á–∞–Ω–∫–∞
        chunk_id = f"{current_page_id}:{current_chunk_index}"
        last_page_id = current_page_id
        # –î–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
        chunk.metadata["id"] = chunk_id
    return chunks

def clear_database():
    if os.path.exists(CHROMA_PATH):
        shutil.rmtree(CHROMA_PATH)

if __name__ == "__main__":
    main()
